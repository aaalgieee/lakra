# Frequently Asked Questions (FAQ)

## General Questions

### What is Lakra?

Lakra is a comprehensive annotation system designed for machine translation quality assessment. It allows users to evaluate the quality of machine translations, identify errors, and provide feedback for research purposes.

### Who can use Lakra?

Lakra is designed for:
- **Annotators**: People who evaluate machine translation quality
- **Evaluators**: Experts who assess annotation quality
- **Researchers**: Academic researchers studying machine translation
- **Administrators**: System managers and coordinators

### What languages are supported?

Lakra currently supports multiple language pairs, including:
- English (en)
- Spanish (es)
- Filipino (fil)
- Cebuano (ceb)
- Hiligaynon (hil)
- Waray (war)
- Tagalog (tgl)

New languages can be added based on research needs.

### Is Lakra free to use?

Lakra is primarily an academic research tool. Access is typically provided to research participants and institutional users. Contact the administrator for access information.

## Getting Started

### How do I create an account?

1. Visit the registration page
2. Fill in your email, username, password, and personal information
3. Select your language preferences
4. Complete the onboarding test
5. Start annotating once approved

### What is the onboarding test?

The onboarding test ensures you understand:
- Annotation guidelines and quality criteria
- Error classification system
- Platform interface and workflow
- Consistency standards

You must achieve a minimum score (typically 80%) to begin annotating.

### How long does the onboarding test take?

The onboarding test typically takes 60-90 minutes to complete. You can take breaks during the test, but there may be a time limit for each section.

### What happens if I fail the onboarding test?

If you don't pass the onboarding test:
- Review the feedback provided
- Study the areas where you struggled
- Retake the test when ready (limited attempts available)
- Contact support for additional help if needed

## Using the System

### How do I start annotating?

1. Login to your account
2. Click "Start Annotating" from the dashboard
3. The system will assign you a sentence to annotate
4. Follow the annotation interface to complete your work
5. Submit your annotation when finished

### How long should each annotation take?

Annotation time varies based on:
- Text complexity and length
- Number of errors found
- Your experience level
- Domain familiarity

Typically, annotations take 10-30 minutes each.

### Can I save my work and continue later?

Yes! The system auto-saves your progress. You can:
- Leave an annotation incomplete and return later
- Save drafts of your work
- Resume from where you left off
- Access your work from any device

### What if I make a mistake?

Before submission:
- Edit your annotation directly
- Modify scores, comments, or classifications
- Review your work before submitting

After submission:
- Contact an administrator for corrections
- Learn from evaluator feedback
- Apply lessons to future annotations

## Annotation Process

### How do I rate translation quality?

Use the 1-5 scale for each criterion:

**Fluency (Grammar and Naturalness):**
- 5: Perfect, sounds completely natural
- 4: Good, minor issues
- 3: Fair, noticeable problems
- 2: Poor, significant issues
- 1: Very poor, nearly unreadable

**Adequacy (Meaning Preservation):**
- 5: Perfect meaning preservation
- 4: Good, minor meaning differences
- 3: Fair, some meaning loss
- 2: Poor, significant meaning changes
- 1: Very poor, major meaning distortion

**Overall Quality:**
- 5: Professional quality
- 4: Good quality, minor editing needed
- 3: Acceptable, moderate editing needed
- 2: Poor quality, major editing required
- 1: Unacceptable, needs retranslation

### What are error types?

**Minor Syntax/Terminology (MI_ST):**
- Small grammatical errors
- Minor word choice issues
- Punctuation problems

**Minor Semantic (MI_SE):**
- Slight meaning differences
- Nuance variations
- Minor omissions

**Major Syntax/Terminology (MA_ST):**
- Serious grammatical errors
- Sentence structure problems
- Major terminology errors

**Major Semantic (MA_SE):**
- Significant meaning changes
- Major omissions or additions
- Complete mistranslations

### How do I highlight errors?

1. Select the problematic text in the translation
2. Choose the appropriate error type from the dropdown
3. Add a specific comment explaining the issue
4. Repeat for all errors found

### Should I provide a corrected translation?

Yes, when possible:
- Provide a corrected version in the "Final Form" field
- Ensure your correction is accurate and natural
- Maintain the same style and tone as the original
- Focus on fixing the identified errors

### What about voice recordings?

Voice recordings are optional but helpful for:
- Demonstrating correct pronunciation
- Explaining complex corrections
- Providing audio feedback
- Helping with pronunciation research

## Technical Issues

### The system is running slowly

Try these solutions:
- Refresh your browser
- Clear browser cache and cookies
- Use a supported browser (Chrome, Firefox, Safari, Edge)
- Check your internet connection
- Try a different device

### I can't log in

Common solutions:
- Check your email and password
- Ensure Caps Lock is off
- Try password reset if forgotten
- Clear browser cache
- Contact support if problems persist

### The interface looks broken

This might be due to:
- Outdated browser version
- Disabled JavaScript
- Browser extensions interfering
- Cache issues

Try:
- Update your browser
- Disable browser extensions
- Clear cache and cookies
- Try incognito/private browsing mode

### I can't hear audio

For voice recording features:
- Check your microphone permissions
- Ensure microphone is connected
- Try a different browser
- Check system audio settings
- Contact support for technical help

## Quality and Feedback

### How is my work evaluated?

Experienced evaluators review your annotations and provide:
- Quality scores for your annotation accuracy
- Specific feedback on areas for improvement
- Recognition of good work
- Suggestions for better practices

### What if I disagree with feedback?

If you disagree with evaluator feedback:
- Review the feedback carefully
- Consider the evaluator's perspective
- Discuss with your supervisor if needed
- Use it as a learning opportunity
- Focus on improving future work

### How can I improve my annotation quality?

To improve your annotations:
- Read feedback carefully and apply suggestions
- Practice regularly and consistently
- Study the annotation guidelines
- Ask questions when uncertain
- Learn from other annotators' good practices

### What is inter-annotator agreement?

Inter-annotator agreement measures how consistently different annotators evaluate the same content. High agreement indicates:
- Clear and well-applied guidelines
- Consistent quality standards
- Effective training and calibration
- Reliable annotation data

## Administrative Questions

### How do I change my language preferences?

1. Go to your Profile settings
2. Select "Language Preferences"
3. Choose your preferred languages
4. Save changes

Your preferences help the system assign appropriate content.

### Can I change my username or email?

- **Username**: Usually cannot be changed after creation
- **Email**: May be changeable through profile settings
- **Other details**: Can typically be updated in profile settings

Contact support for help with account changes.

### How do I reset my password?

1. Go to the login page
2. Click "Forgot Password"
3. Enter your email address
4. Check your email for reset instructions
5. Follow the link to create a new password

### What if I want to delete my account?

To delete your account:
- Contact system administrators
- Request account deletion
- Understand that this may affect research data
- Consider deactivation instead of deletion

## Research and Data

### How is my data used?

Your annotation data is used for:
- Machine translation research
- Quality assessment studies
- System improvement
- Academic publications

All data is anonymized and used according to ethical research standards.

### Can I access my annotation history?

Yes! You can:
- View all your completed annotations
- See your performance statistics
- Review feedback received
- Track your improvement over time

### What happens to the data I annotate?

Annotation data is:
- Stored securely in the system
- Used for research purposes
- Anonymized for analysis
- Shared according to research agreements
- Retained based on institutional policies

### Can I contribute to research publications?

Depending on your contribution level:
- Significant contributors may be acknowledged
- Major contributors might be co-authors
- All contributors support important research
- Publication policies vary by project

## Support and Help

### Where can I get help?

Help is available through:
- **Documentation**: Comprehensive guides and manuals
- **Support Team**: Technical and annotation support
- **Training Team**: Guidance on annotation practices
- **Community**: Other annotators and users
- **Administrators**: System management and access

### How do I report a bug?

To report technical issues:
1. Note the exact error message
2. Record steps to reproduce the problem
3. Include your browser and system information
4. Contact technical support with details
5. Provide screenshots if helpful

### How do I suggest improvements?

We welcome suggestions for:
- Interface improvements
- Feature requests
- Process enhancements
- Documentation updates
- Training materials

Submit suggestions through the feedback system or contact administrators.

### What are the system requirements?

**Minimum Requirements:**
- Modern web browser (Chrome, Firefox, Safari, Edge)
- Stable internet connection
- JavaScript enabled
- Screen resolution 1024x768 or higher

**Recommended:**
- Latest browser versions
- High-speed internet
- Larger screen for better experience
- Microphone for voice features

### Is there mobile support?

The system is primarily designed for desktop use. Mobile support is limited because:
- Complex annotation interfaces work better on larger screens
- Precise text selection is easier with a mouse
- Multiple panels and features need screen space
- Voice recording works better on desktop

## Troubleshooting

### My annotations aren't saving

Check these issues:
- Ensure you're logged in
- Check your internet connection
- Complete all required fields
- Try refreshing the page
- Contact support if problems persist

### The text selection isn't working

This might be due to:
- JavaScript being disabled
- Browser compatibility issues
- Page not fully loaded
- Browser extensions interfering

Try:
- Enabling JavaScript
- Using a different browser
- Disabling browser extensions
- Refreshing the page

### I can't access certain features

Feature access depends on:
- Your user role (annotator, evaluator, admin)
- Onboarding completion status
- Account activation status
- System permissions

Contact administrators if you believe you should have access.

### The system keeps logging me out

This happens when:
- Your session expires (typically after 30 minutes)
- You're inactive for too long
- There are authentication issues
- Multiple devices are being used

Solutions:
- Log in again
- Check "Remember Me" if available
- Ensure cookies are enabled
- Use only one device at a time

## Best Practices

### How can I be a good annotator?

Follow these best practices:
- Read guidelines thoroughly
- Be consistent in your evaluations
- Provide detailed, helpful comments
- Take breaks to maintain focus
- Ask questions when uncertain
- Learn from feedback
- Collaborate well with others

### What should I do if I'm unsure about something?

When uncertain:
- Review the annotation guidelines
- Check similar examples if available
- Ask for clarification from supervisors
- Err on the side of being thorough
- Document your reasoning
- Learn from the experience

### How do I maintain consistency?

To stay consistent:
- Apply the same standards to all annotations
- Use the full range of quality scores
- Reference guidelines regularly
- Take notes on difficult decisions
- Participate in calibration sessions
- Learn from other annotators

---

## Still Have Questions?

If you can't find the answer to your question:

- **Check the Documentation**: [User Manual](../user-manual.md), [Installation Guide](../installation.md)
- **Contact Support**: [Support Information](contact.md)
- **Join the Community**: [Resources and Forums](resources.md)
- **Report Issues**: [Known Issues](known-issues.md)

**Last Updated**: January 2024
**FAQ Version**: 1.0.0 